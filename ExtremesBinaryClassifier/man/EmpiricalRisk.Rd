% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions.R
\name{EmpiricalRisk}
\alias{EmpiricalRisk}
\title{A Risk estimation function}
\usage{
EmpiricalRisk(Y, Y.eps = NULL, g, g.eps = NULL, epsilon = 0)
}
\arguments{
\item{Y}{vector of the true binary outcomes}

\item{Y.eps}{vector of the true binary outcomes in the extreme region}

\item{g}{vector of the predicted binary outcomes from a given classifier}

\item{g.eps}{vector of the predicted binary outcomes in the extreme region from the same classifier}

\item{epsilon}{single numeric between 0 and 1 giving the amount of data we want to remove}
}
\description{
Compute the empirical risk defined ???? given the output of a classifier g and the true binary outcomes Y. If epsilon>0, supply the values of the trained classifier on the thresholded data g.eps and the true binary outcomes Y.eps := +1 if H > eps_u and -1 otherwise.
}
\details{
to add
}
\examples{
require(rpart)

set.seed(123)
## Reproduce the simulation example from Legrand et al.
nsim <- 1e4
X1 <- 1/(runif(nsim)^(1/3))
X2 <- 1/(runif(nsim)^(1/2))
P <- 1/(runif(nsim)^(1/2))
H <- X1 + P
## Compute the two thresholds u and epsilon_u
u <- quantile(H,probs=0.97)
eps <- 0.7
eps_u <- u*eps
## Split data between training and testing sets
ii <- sample.int(length(H), size = 0.7*length(H), replace=F)
Xtrain <- cbind(X1[ii], X2[ii])
Xtest <- cbind(X1[-ii], X2[-ii])
Htrain <- H[ii]
Htest <- H[-ii]

## Linear classifier
## Train the linear classifier
init <- lm(H ~ X1 + X2, data = data.frame(H = H, X1 = X1, X2 = X2))$coefficients[2:3]
linclass <- LinearClassifier(X = Xtrain, thresh = eps_u, H = Htrain, initials = init)
## Compute the predicted binary outcome on the test set from all the data and only with the extreme region data
glin <- 2*(as.vector(linclass$theta \%*\% t(Xtest)) > u) - 1
glineps <- 2*(as.vector(linclass$theta \%*\% t(Xtest)) > eps_u) - 1
## Compute the true binary outcome on the test set from all the data and only with the extreme region data
Ytesteps <- 2*(Htest > eps_u) - 1
Ytest <- 2*(Htest > u) - 1
EmpiricalRisk(Y = Ytest, Y.eps = Ytesteps, g = glin, g.eps = glineps, epsilon = eps)

## Comparison with regression tree
Ytraineps <- 2*(Htrain > eps_u) - 1
treeclass <- rpart(y~., data=data.frame(x=Xtrain, y = as.factor(Ytraineps)), method = "class")
gtree <- as.numeric(predict(treeclass, newdata = data.frame(x = Xtest, y = Ytest), type="class"))
gtreeeps <- as.numeric(predict(treeclass, newdata = data.frame(x = Xtest, y = Ytesteps), type = 'class'))
EmpiricalRisk(Y = Ytest, Y.eps = Ytesteps, g = gtree, g.eps = gtreeeps, epsilon = eps)
}
\references{
Legrand et al.
}
\seealso{
\link{LinearClassifier}
}
